{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Classification with Keras\n",
    "\n",
    "Keras exists to make coding deep neural networks simpler. To demonstrate just how easy it is, you’re going to use Keras to build a convolutional neural network in a few dozen lines of code.\n",
    "\n",
    "You’ll be connecting the concepts from the previous lessons to the methods that Keras provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The network you'll build with Keras is similar to the example that you can find in Keras’s GitHub repository that builds out a [convolutional neural network for MNIST](https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py). \n",
    "\n",
    "However, instead of using the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset, you're going to use the [German Traffic Sign Recognition Benchmark](http://benchmark.ini.rub.de/?section=gtsrb&subsection=news) dataset that you've used previously.\n",
    "\n",
    "You can download pickle files with sanitized traffic sign data here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Here are the steps you'll take to build the network:\n",
    "\n",
    "1. First load the data.\n",
    "2. Build a feedforward neural network to classify traffic signs.\n",
    "3. Build a convolutional neural network to classify traffic signs.\n",
    "\n",
    "Keep an eye on the network’s accuracy over time. Once the accuracy reaches the 98% range, you can be confident that you’ve built and trained an effective model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "Start by importing the data from the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8036, 7)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import os.path\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = '/hamidb/applications/udacity-carnd/repo/data'\n",
    "headers = [\"center\", \"left\", \"right\", \"steer_angle\",\n",
    "           \"throttle\", \"break\", \"speed\"]\n",
    "logs = []\n",
    "for setpath in sorted(glob.glob(data_dir+\"/*\")):\n",
    "    setname = os.path.basename(setpath)\n",
    "    for contents in os.listdir(setpath):\n",
    "        if fnmatch.fnmatch(contents,'*.csv'):\n",
    "            log_file = os.path.join(setpath, contents)\n",
    "            \n",
    "            log = pd.read_csv(log_file, header=None, names=headers, skiprows=1)\n",
    "            logs.append(log)\n",
    "    \n",
    "logs = pd.concat(logs, axis=0, ignore_index=True)\n",
    "\n",
    "print(logs.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8036, 128, 128, 3)\n",
      "(8036,)\n",
      "train size: 6508\n",
      "valid size: 724\n",
      "test size: 804\n",
      "input shape: (128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "dir_prefix = \"/hamidb/applications/udacity-carnd/repo/data/set1\"\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "target_size = (64, 64)\n",
    "\n",
    "def batch_generator(batch_size, data):\n",
    "    \n",
    "    \n",
    "for item in zip(logs['center'], logs['steer_angle']):\n",
    "    img = image.load_img(os.path.join(dir_prefix, item[0]), target_size=(128, 128))\n",
    "    x = image.img_to_array(img)\n",
    "    #x = x[60:,:,:]\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features.append(x[0])\n",
    "    labels.append(item[1])\n",
    "\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# Get randomized datasets for training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size=0.10,\n",
    "    random_state=43)\n",
    "\n",
    "# Get randomized datasets for training and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.10,\n",
    "    random_state=43)\n",
    "\n",
    "# Print out shapes of new arrays\n",
    "train_size = X_train.shape[0]\n",
    "test_size = X_test.shape[0]\n",
    "valid_size = X_valid.shape[0]\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"valid size:\", valid_size)\n",
    "print(\"test size:\", test_size)\n",
    "print(\"input shape:\", input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_file = 'simulator.pickle'\n",
    "\n",
    "with open(pickle_file, 'wb') as pfile:\n",
    "    pickle.dump({'train_dataset': X_train,\n",
    "                 'train_labels': y_train,\n",
    "                 'valid_dataset': X_valid,\n",
    "                 'valid_labels': y_valid,\n",
    "                 'test_dataset': X_test,\n",
    "                 'test_labels': y_test,},\n",
    "                pfile, pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 128, 128, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 128, 128, 64)  0           input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 128, 128, 64)  0           block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 64, 64, 64)    0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 64, 64, 128)   0           block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 64, 64, 128)   0           block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 32, 32, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 32, 32, 256)   0           block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 32, 32, 256)   0           block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 32, 32, 256)   0           block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 16, 16, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 16, 16, 512)   0           block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 16, 16, 512)   0           block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 16, 16, 512)   0           block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 8, 8, 512)     0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 8, 8, 512)     0           block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 8, 8, 512)     0           block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 8, 8, 512)     0           block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 4, 4, 512)     0           block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "globalaveragepooling2d_1 (Global (None, 512)           0           block5_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_26 (Dense)                 (None, 1024)          525312      globalaveragepooling2d_1[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 1024)          0           dense_26[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_27 (Dense)                 (None, 512)           524800      dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 512)           0           dense_27[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_28 (Dense)                 (None, 256)           131328      dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 256)           0           dense_28[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_29 (Dense)                 (None, 1)             257         dropout_18[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1181697\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16 as vgg16\n",
    "from keras.layers import Dense, Input, AveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "base_model = vgg16(weights='imagenet', input_tensor=Input((64, 64, 3)), include_top=False)\n",
    "\n",
    "# freeze all convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1)(x)\n",
    "\n",
    "#x = BatchNormalization()(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "#x = Flatten()(x)\n",
    "#x = Dense(4096, activation=\"relu\")(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dense(2048, activation=\"relu\")(x)\n",
    "# x = Dense(2048, activation=\"relu\")(x)\n",
    "# x = Dense(1024, activation=\"relu\")(x)\n",
    "# x = Dense(1, activation=\"linear\")(x)\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6508 samples, validate on 724 samples\n",
      "Epoch 1/9\n",
      "6508/6508 [==============================] - 3364s - loss: 0.0332 - acc: 0.5353 - mean_absolute_error: 0.0935 - val_loss: 0.0184 - val_acc: 0.5387 - val_mean_absolute_error: 0.0787\n",
      "Epoch 2/9\n",
      "6508/6508 [==============================] - 3364s - loss: 0.0168 - acc: 0.5403 - mean_absolute_error: 0.0758 - val_loss: 0.0180 - val_acc: 0.5387 - val_mean_absolute_error: 0.0778\n",
      "Epoch 3/9\n",
      "6508/6508 [==============================] - 3363s - loss: 0.0168 - acc: 0.5403 - mean_absolute_error: 0.0761 - val_loss: 0.0182 - val_acc: 0.5387 - val_mean_absolute_error: 0.0817\n",
      "Epoch 4/9\n",
      "6508/6508 [==============================] - 3358s - loss: 0.0167 - acc: 0.5403 - mean_absolute_error: 0.0756 - val_loss: 0.0180 - val_acc: 0.5387 - val_mean_absolute_error: 0.0748\n",
      "Epoch 5/9\n",
      "6508/6508 [==============================] - 3366s - loss: 0.0167 - acc: 0.5403 - mean_absolute_error: 0.0741 - val_loss: 416586848253583622144.0000 - val_acc: 0.0000e+00 - val_mean_absolute_error: 1973724170.1789\n",
      "Epoch 6/9\n",
      "6508/6508 [==============================] - 3363s - loss: 0.0167 - acc: 0.5403 - mean_absolute_error: 0.0744 - val_loss: 0.0180 - val_acc: 0.5387 - val_mean_absolute_error: 0.0746\n",
      "Epoch 7/9\n",
      "6508/6508 [==============================] - 3375s - loss: 0.0166 - acc: 0.5403 - mean_absolute_error: 0.0746 - val_loss: 0.0181 - val_acc: 0.5387 - val_mean_absolute_error: 0.0739\n",
      "Epoch 8/9\n",
      "6508/6508 [==============================] - 3365s - loss: 0.0166 - acc: 0.5403 - mean_absolute_error: 0.0733 - val_loss: 0.0181 - val_acc: 0.5387 - val_mean_absolute_error: 0.0723\n",
      "Epoch 9/9\n",
      "6508/6508 [==============================] - 3376s - loss: 0.0166 - acc: 0.5403 - mean_absolute_error: 0.0728 - val_loss: 0.0180 - val_acc: 0.5387 - val_mean_absolute_error: 0.0761\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compile and train the model here.\n",
    "batch_size = 64\n",
    "nb_epoch = 9\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy', 'mean_absolute_error'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_valid, y_valid))\n",
    "#validation_split=0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 4s     \n",
      "Test score: 0.00970136054792\n",
      "Test accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test[0:100], y_test[0:100], verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import h5py\n",
    "\n",
    "with open('model.json', 'w') as f:\n",
    "    json.dump(model.to_json(), f)\n",
    "\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "Compile and train the network for 2 epochs. [Use the `adam` optimizer, with `categorical_crossentropy` loss.](https://keras.io/models/sequential/)\n",
    "\n",
    "Hint 1: In order to use categorical cross entropy, you will need to [one-hot encode the labels](https://github.com/fchollet/keras/blob/master/keras/utils/np_utils.py).\n",
    "\n",
    "Hint 2: In order to pass the input images to the fully-connected hidden layer, you will need to [reshape the input](https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py).\n",
    "\n",
    "Hint 3: Keras's `.fit()` method returns a `History.history` object, which the tests below use. Save that to a variable named `history`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations\n",
    "You've built a feedforward neural network in Keras!\n",
    "\n",
    "Don't stop here! Next, you'll add a convolutional layer to drive.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation Accuracy**: (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "Once you've picked out your best model, it's time to test it.\n",
    "\n",
    "Load up the test data and use the [`evaluate()` method](https://keras.io/models/model/#evaluate) to see how well it does.\n",
    "\n",
    "Hint 1: After you load your test data, don't forget to normalize the input and one-hot encode the output, so it matches the training data.\n",
    "\n",
    "Hint 2: The `evaluate()` method should return an array of numbers. Use the `metrics_names()` method to get the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./test.p', mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_test = test['features']\n",
    "y_test = test['labels']\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "X_test -= 0.5\n",
    "Y_test = np_utils.to_categorical(y_test, 43)\n",
    "\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Accuracy:** (fill in here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Keras is a great tool to use if you want to quickly build a neural network and evaluate performance."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
